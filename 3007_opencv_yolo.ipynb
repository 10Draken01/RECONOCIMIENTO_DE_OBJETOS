{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29b82dac-aa3a-4ec5-9cb6-192cc960d5da",
   "metadata": {},
   "source": [
    "## Detección de objetos con YOLO y OpenCV\n",
    "\n",
    "El algoritmo YOLO revolucionó la detección de objetos al introducir un enfoque unificado que divide la imagen en una cuadrícula y predice cuadros delimitadores y probabilidades de clase dentro de cada celda de la cuadrícula. A diferencia de otros algoritmos que se basan en ventanas deslizantes o propuestas de regiones, YOLO realiza la detección en una sola pasada.\n",
    "1. **Rendimiento en tiempo real**: la arquitectura de YOLO le permite lograr la detección de objetos en tiempo real, lo que lo hace adecuado para aplicaciones que requieren resultados rápidos y precisos.\n",
    "2. **Simplicidad y eficiencia**: el diseño de una sola pasada de YOLO simplifica el proceso de detección y lo hace más eficiente computacionalmente en comparación con otros algoritmos.\n",
    "3. **Robustez**: YOLO funciona bien incluso en imágenes con múltiples objetos u objetos de diferentes tamaños, gracias a su enfoque basado en cuadrícula."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75b4033-91b2-4a28-8af1-24e71f195128",
   "metadata": {},
   "source": [
    "### Configuración del entorno\n",
    "1. Instalar las bibliotecas necesarias: comience instalando las bibliotecas necesarias, incluidas Ultralytics YOLO, OpenCV y cvzone. Puede usar pip o conda para instalar estas bibliotecas según sus preferencias.\n",
    "2. Descargar los pesos de YOLO: YOLO requiere pesos entrenados previamente para realizar la detección de objetos. Puede descargar el archivo de pesos del repositorio oficial de Ultralytics o utilizar una fuente alternativa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2eac06-e617-46fc-96e3-fb082dc3d20b",
   "metadata": {},
   "source": [
    "### Cargando el modelo YOLO\n",
    "1. Importe las bibliotecas necesarias: comience importando las bibliotecas necesarias, incluidas YOLO del paquete Ultralytics, cv2 (OpenCV) y math.\n",
    "2. Configurar el modelo YOLO: inicialice una instancia de la clase YOLO y cargue los pesos YOLO utilizando la ruta al archivo de pesos que descargó anteriormente.\n",
    "3. Definir los nombres de las clases: crear una lista de nombres de clases correspondientes a las clases de salida del modelo YOLO. Los nombres de las clases suelen estar disponibles en la documentación o el conjunto de datos utilizados para entrenar el modelo YOLO.\n",
    "\n",
    "https://docs.ultralytics.com/tasks/detect/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20cea0dd-eea8-483c-8083-25a0966f37a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T19:16:16.181595Z",
     "iopub.status.busy": "2024-07-18T19:16:16.180592Z",
     "iopub.status.idle": "2024-07-18T19:16:54.857817Z",
     "shell.execute_reply": "2024-07-18T19:16:54.856809Z",
     "shell.execute_reply.started": "2024-07-18T19:16:16.181595Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolo_model\\yolov8n.pt': 100%|██████████| 6.25M/6.25M [00:00<00:00, 9.17MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No se puede recibir fotograma. Saliendo ...\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import  cv2\n",
    "import cvzone\n",
    "import math\n",
    "\n",
    "#cap = cv2.VideoCapture(0)\n",
    "cap = cv2.VideoCapture('./video/video1.MP4')\n",
    "cap.set(3, 1280)\n",
    "cap.set(4, 720)\n",
    "\n",
    "model = YOLO('./yolo_model/yolov8n.pt')\n",
    "\n",
    "classNames =[\"persona\",\n",
    "\"bicicleta\",\n",
    "\"coche\",\n",
    "\"motocicleta\",\n",
    "\"avión\",\n",
    "\"autobús\",\n",
    "\"tren\",\n",
    "\"camión\",\n",
    "\"barco\",\n",
    "\"semáforo\",\n",
    "\"hidrante\",\n",
    "\"señal de stop\",\n",
    "\"parquímetro\",\n",
    "\"banco\",\n",
    "\"pájaro\",\n",
    "\"gato\",\n",
    "\"perro\",\n",
    "\"caballo\",\n",
    "\"oveja\",\n",
    "\"vaca\",\n",
    "\"elefante\",\n",
    "\"oso\",\n",
    "\"cebra\",\n",
    "\"jirafa\",\n",
    "\"mochila\",\n",
    "\"paraguas\",\n",
    "\"bolso\",\n",
    "\"corbata\",\n",
    "\"maleta\",\n",
    "\"frisbee\",\n",
    "\"esquís\",\n",
    "\"tabla de snowboard\",\n",
    "\"pelota de deporte\",\n",
    "\"cometa\",\n",
    "\"bate de béisbol\",\n",
    "\"guante de béisbol\",\n",
    "\"monopatín\",\n",
    "\"tabla de surf\",\n",
    "\"raqueta de tenis\",\n",
    "\"botella\",\n",
    "\"copa de vino\",\n",
    "\"taza\",\n",
    "\"tenedor\",\n",
    "\"cuchillo\",\n",
    "\"cuchara\",\n",
    "\"cuenco\",\n",
    "\"plátano\",\n",
    "\"manzana\",\n",
    "\"sándwich\",\n",
    "\"naranja\",\n",
    "\"brócoli\",\n",
    "\"zanahoria\",\n",
    "\"perrito caliente\",\n",
    "\"pizza\",\n",
    "\"donut\",\n",
    "\"pastel\",\n",
    "\"silla\",\n",
    "\"sofá\",\n",
    "\"planta en maceta\",\n",
    "\"cama\",\n",
    "\"mesa de comedor\",\n",
    "\"inodoro\",\n",
    "\"televisor\",\n",
    "\"portátil\",\n",
    "\"ratón\",\n",
    "\"control remoto\",\n",
    "\"teclado\",\n",
    "\"teléfono móvil\",\n",
    "\"microondas\",\n",
    "\"horno\",\n",
    "\"tostadora\",\n",
    "\"fregadero\",\n",
    "\"nevera\",\n",
    "\"libro\",\n",
    "\"reloj\",\n",
    "\"jarrón\",\n",
    "\"tijeras\",\n",
    "\"oso de peluche\",\n",
    "\"secador de pelo\",\n",
    "\"cepillo de dientes\"]\n",
    "\n",
    "while True:\n",
    "    success, img  =cap.read()\n",
    "    if not success:\n",
    "        print(\"No se puede recibir fotograma. Saliendo ...\")\n",
    "        break\n",
    "    results = model(img, stream=True)\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "            w, h = x2-x1, y2-y1\n",
    "            cvzone.cornerRect(img, (x1, y1, w, h))\n",
    "\n",
    "            conf = math.ceil((box.conf[0]*100))/100\n",
    "\n",
    "            cls = box.cls[0]\n",
    "            name = classNames[int(cls)]\n",
    "\n",
    "            cvzone.putTextRect(img, f'{name} 'f'{conf}', (max(0,x1), max(35,y1)), scale = 1,thickness=2,font=cv2.FONT_HERSHEY_PLAIN,offset=10)\n",
    "    cv2.imshow(\"Image\", img)\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18767191",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5801f38a-33ad-46d1-86e8-40b9258ebb42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T19:01:48.575788Z",
     "iopub.status.busy": "2024-07-18T19:01:48.562795Z",
     "iopub.status.idle": "2024-07-18T19:01:48.595782Z",
     "shell.execute_reply": "2024-07-18T19:01:48.594885Z",
     "shell.execute_reply.started": "2024-07-18T19:01:48.575788Z"
    }
   },
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840f0381",
   "metadata": {},
   "source": [
    "### Detección de objetos\n",
    "La detección de objetos mediante cajas delimitadoras es una técnica de visión artificial que implica detectar y localizar objetos en una imagen dibujando una caja delimitadora alrededor de cada objeto.\n",
    "\n",
    "### Segmentación de instancias\n",
    "La segmentación de instancias es una técnica de visión artificial que implica la identificación y localización de objetos en una imagen a nivel de píxel. A diferencia de la segmentación semántica, que sólo clasifica cada píxel, la segmentación de instancias distingue entre diferentes instancias de la misma clase.\n",
    "\n",
    "### Estimación de pose\n",
    "La estimación de pose es una técnica utilizada para determinar la pose del objeto en relación con la cámara o el sistema de coordenadas mundial. Esto implica la identificación de puntos clave o articulaciones en objetos, particularmente humanos o animales.\n",
    "\n",
    "\n",
    "### Clasificación\n",
    "La clasificación de imágenes es una tarea de visión artificial que implica categorizar una imagen en una o más clases o categorías predefinidas según su contenido visual.\n",
    "\n",
    "### Cajas delimitadoras orientadas (OBB)\n",
    "Las cajas delimitadoras orientadas (OBB) son un método en la visión artificial para detectar objetos en ángulo en imágenes utilizando cajas delimitadoras rotadas, a menudo aplicado a imágenes aéreas y de satélite. A diferencia de las cajas delimitadoras tradicionales, las OBB pueden ajustarse mejor a los objetos en varias orientaciones.\n",
    "\n",
    "\n",
    "### Seguimiento de múltiples objetos\n",
    "El seguimiento de múltiples objetos es una técnica de visión artificial que implica la detección y el seguimiento de múltiples objetos a lo largo del tiempo en una secuencia de vídeo. Esta tarea amplía la detección de objetos manteniendo identidades consistentes de los objetos a través de los fotogramas.\n",
    "\n",
    "https://docs.ultralytics.com/es/datasets/#classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d62da0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afef94c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
