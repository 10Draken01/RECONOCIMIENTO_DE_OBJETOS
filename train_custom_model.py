"""
Script de entrenamiento para el dataset de Roboflow
Entrena el modelo de lÃ¡piz usando el dataset ya etiquetado
"""

import os
import yaml
from ultralytics import YOLO
import torch
from pathlib import Path
import shutil
from datetime import datetime

def verify_roboflow_dataset():
    """Verificar que el dataset de Roboflow estÃ© completo"""
    print("ğŸ” Verificando dataset de Roboflow...")
    
    dataset_path = Path("dataset_lapiz")
    
    # Verificar estructura
    required_dirs = [
        dataset_path / "train" / "images",
        dataset_path / "train" / "labels",
        dataset_path / "valid" / "images", 
        dataset_path / "valid" / "labels",
        dataset_path / "test" / "images",
        dataset_path / "test" / "labels"
    ]
    
    for dir_path in required_dirs:
        if not dir_path.exists():
            print(f"âŒ Falta directorio: {dir_path}")
            return False
        
        file_count = len(list(dir_path.glob("*")))
        print(f"âœ… {dir_path.parent.name}/{dir_path.name}: {file_count} archivos")
    
    # Verificar data.yaml
    yaml_path = dataset_path / "data.yaml"
    if yaml_path.exists():
        print(f"âœ… Archivo data.yaml encontrado")
        
        # Leer contenido
        try:
            with open(yaml_path, 'r') as f:
                data_config = yaml.safe_load(f)
            
            print(f"ğŸ“Š Dataset configuraciÃ³n:")
            print(f"   â€¢ Clases: {data_config.get('nc', 'N/A')}")
            print(f"   â€¢ Nombres: {data_config.get('names', [])}")
            
        except Exception as e:
            print(f"âš ï¸ Error leyendo data.yaml: {e}")
    else:
        print("âŒ No se encontrÃ³ data.yaml")
        return False
    
    return True

def validate_sample_labels():
    """Verificar algunas etiquetas para asegurar formato correcto"""
    print("ğŸ·ï¸ Verificando formato de etiquetas...")
    
    dataset_path = Path("dataset_lapiz")
    
    # Verificar algunas etiquetas de train
    train_labels = list((dataset_path / "train" / "labels").glob("*.txt"))
    
    if not train_labels:
        print("âŒ No se encontraron etiquetas en train")
        return False
    
    valid_labels = 0
    issues = []
    
    # Verificar primeras 5 etiquetas
    for label_file in train_labels[:5]:
        try:
            with open(label_file, 'r') as f:
                lines = f.readlines()
            
            for line_num, line in enumerate(lines, 1):
                line = line.strip()
                if not line:
                    continue
                
                parts = line.split()
                if len(parts) != 5:
                    issues.append(f"{label_file.name}:{line_num} - Formato incorrecto: {line}")
                    continue
                
                try:
                    class_id, x, y, w, h = map(float, parts)
                    
                    # Verificar rangos
                    if not (0 <= x <= 1 and 0 <= y <= 1 and 0 <= w <= 1 and 0 <= h <= 1):
                        issues.append(f"{label_file.name}:{line_num} - Coordenadas fuera de rango")
                    else:
                        valid_labels += 1
                        
                except ValueError:
                    issues.append(f"{label_file.name}:{line_num} - Valores no numÃ©ricos")
        
        except Exception as e:
            issues.append(f"{label_file.name} - Error leyendo archivo: {e}")
    
    if issues:
        print(f"âš ï¸ Encontrados {len(issues)} problemas:")
        for issue in issues[:3]:  # Mostrar solo los primeros 3
            print(f"   â€¢ {issue}")
        if len(issues) > 3:
            print(f"   ... y {len(issues) - 3} mÃ¡s")
        
        if valid_labels == 0:
            print("âŒ No se encontraron etiquetas vÃ¡lidas")
            return False
    
    print(f"âœ… Etiquetas vÃ¡lidas encontradas: {valid_labels}")
    return True

def train_lapiz_model():
    """Entrenar modelo de lÃ¡piz con dataset de Roboflow"""
    print("ğŸš€ Iniciando entrenamiento del modelo de lÃ¡piz...")
    
    dataset_path = Path("dataset_lapiz")
    yaml_path = dataset_path / "data.yaml"
    
    if not yaml_path.exists():
        print(f"âŒ No se encontrÃ³ {yaml_path}")
        return None
    
    # Cargar modelo base YOLOv8
    print("ğŸ“¦ Cargando modelo base YOLOv8n...")
    model = YOLO('yolov8n.pt')
    
    # ConfiguraciÃ³n de entrenamiento
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    project_name = f"lapiz_roboflow_{timestamp}"
    
    print(f"ğŸ¯ ConfiguraciÃ³n de entrenamiento:")
    print(f"   â€¢ Proyecto: {project_name}")
    print(f"   â€¢ Dataset: {yaml_path}")
    print(f"   â€¢ Modelo base: YOLOv8n")
    print(f"   â€¢ Epochs: 100")
    print(f"   â€¢ Batch size: 16")
    print(f"   â€¢ Image size: 640")
    print(f"   â€¢ Device: {'GPU' if torch.cuda.is_available() else 'CPU'}")
    print(f"   â€¢ Optimizaciones: Activadas")
    
    try:
        print("\nğŸƒâ€â™‚ï¸ Iniciando entrenamiento...")
        print("â³ Esto puede tomar 10-30 minutos dependiendo de tu hardware...")
        
        # Entrenar con configuraciÃ³n optimizada
        results = model.train(
            data=str(yaml_path),
            epochs=100,               # Epochs suficientes
            batch=16,                 # Batch size estÃ¡ndar
            imgsz=640,                # TamaÃ±o de imagen estÃ¡ndar
            device='cpu' if not torch.cuda.is_available() else 0,
            project="models",
            name=project_name,
            
            # ParÃ¡metros de control
            patience=25,              # Parar si no mejora en 25 epochs
            save_period=10,           # Guardar cada 10 epochs
            
            # VisualizaciÃ³n
            verbose=True,
            plots=True,               # Generar grÃ¡ficas
            
            # Data Augmentation (optimizado para lÃ¡pices)
            augment=True,
            mixup=0.1,                # Mezcla de imÃ¡genes
            copy_paste=0.1,           # Copy-paste augmentation
            
            # Transformaciones geomÃ©tricas
            degrees=15,               # RotaciÃ³n Â±15 grados
            translate=0.1,            # TranslaciÃ³n Â±10%
            scale=0.5,                # Escala Â±50%
            shear=5.0,                # Shear Â±5 grados
            perspective=0.0,          # Sin perspectiva (mejor para objetos simples)
            
            # Flip augmentations
            flipud=0.5,               # Volteo vertical
            fliplr=0.5,               # Volteo horizontal
            
            # Mosaic y otras augmentations
            mosaic=1.0,               # Mosaic augmentation
            
            # Augmentaciones de color (suaves para lÃ¡pices)
            hsv_h=0.015,              # VariaciÃ³n de matiz
            hsv_s=0.7,                # VariaciÃ³n de saturaciÃ³n  
            hsv_v=0.4,                # VariaciÃ³n de brillo
            
            # OptimizaciÃ³n del entrenamiento
            lr0=0.01,                 # Learning rate inicial
            lrf=0.1,                  # Learning rate final
            momentum=0.937,           # Momentum
            weight_decay=0.0005,      # Weight decay
            warmup_epochs=3,          # Epochs de calentamiento
            warmup_momentum=0.8,      # Momentum inicial
            warmup_bias_lr=0.1,       # Learning rate inicial para bias
            
            # Configuraciones adicionales
            box=7.5,                  # Box loss weight
            cls=0.5,                  # Classification loss weight
            dfl=1.5,                  # DFL loss weight
            
            # ValidaciÃ³n
            val=True,                 # Validar durante entrenamiento
            save_json=True,           # Guardar resultados en JSON
            
            # Workspace
            exist_ok=True,            # Permitir sobrescribir
            pretrained=True,          # Usar pesos preentrenados
            optimize=False,           # No optimizar para inferencia aÃºn
            keras=False,              # No usar Keras
            resume=False,             # No resumir entrenamiento
            
            # ConfiguraciÃ³n de workers
            workers=8,                # NÃºmero de workers para carga de datos
            
            # ConfiguraciÃ³n de memoria
            close_mosaic=10           # Desactivar mosaic en Ãºltimos N epochs
        )
        
        # Verificar resultados
        best_model_path = Path("models") / project_name / "weights" / "best.pt"
        last_model_path = Path("models") / project_name / "weights" / "last.pt"
        
        if best_model_path.exists():
            # Copiar modelo a ubicaciÃ³n final
            final_model_path = Path("models") / "lapiz_detector.pt"
            shutil.copy2(best_model_path, final_model_path)
            
            print(f"\nğŸ‰ Â¡ENTRENAMIENTO COMPLETADO!")
            print(f"âœ… Mejor modelo guardado en: {final_model_path}")
            
            # Mostrar estadÃ­sticas finales
            print(f"\nğŸ“Š ESTADÃSTICAS DEL ENTRENAMIENTO:")
            print(f"   â€¢ Directorio completo: models/{project_name}")
            print(f"   â€¢ Mejor modelo: {best_model_path}")
            print(f"   â€¢ Ãšltimo modelo: {last_model_path}")
            print(f"   â€¢ GrÃ¡ficas de entrenamiento: models/{project_name}/results.png")
            print(f"   â€¢ MÃ©tricas de validaciÃ³n: models/{project_name}/results.csv")
            
            # Probar el modelo con una imagen de test
            test_model_performance(final_model_path, dataset_path)
            
            return str(final_model_path)
            
        else:
            print("\nâŒ No se encontrÃ³ el modelo entrenado")
            print(f"ğŸ’¡ Revisa la carpeta: models/{project_name}")
            return None
            
    except Exception as e:
        print(f"\nâŒ Error durante entrenamiento: {e}")
        import traceback
        traceback.print_exc()
        return None

def test_model_performance(model_path, dataset_path):
    """Probar el modelo con imÃ¡genes de test"""
    print(f"\nğŸ§ª Probando modelo entrenado...")
    
    try:
        # Cargar modelo entrenado
        model = YOLO(str(model_path))
        
        # Buscar imÃ¡genes de test
        test_images_dir = dataset_path / "test" / "images"
        test_images = list(test_images_dir.glob("*.jpg"))
        
        if test_images:
            print(f"ğŸ–¼ï¸ Probando con {len(test_images)} imÃ¡genes de test...")
            
            total_detections = 0
            successful_images = 0
            
            for i, test_img in enumerate(test_images[:3]):  # Probar solo 3 imÃ¡genes
                try:
                    # Ejecutar predicciÃ³n
                    results = model(str(test_img), conf=0.5)
                    
                    if results and len(results) > 0:
                        detections = len(results[0].boxes) if results[0].boxes else 0
                        total_detections += detections
                        
                        if detections > 0:
                            successful_images += 1
                            print(f"   âœ… {test_img.name}: {detections} lÃ¡pices detectados")
                            
                            # Guardar imagen con predicciones
                            annotated = results[0].plot()
                            import cv2
                            output_path = Path("models") / f"test_prediction_{i+1}.jpg"
                            cv2.imwrite(str(output_path), annotated)
                            
                        else:
                            print(f"   âš ï¸ {test_img.name}: Sin detecciones")
                    else:
                        print(f"   âŒ {test_img.name}: Error en predicciÃ³n")
                        
                except Exception as e:
                    print(f"   âŒ {test_img.name}: Error - {e}")
            
            # Resumen de pruebas
            print(f"\nğŸ“Š RESUMEN DE PRUEBAS:")
            print(f"   â€¢ ImÃ¡genes probadas: {min(3, len(test_images))}")
            print(f"   â€¢ ImÃ¡genes con detecciones: {successful_images}")
            print(f"   â€¢ Total de detecciones: {total_detections}")
            print(f"   â€¢ Promedio por imagen: {total_detections/min(3, len(test_images)):.1f}")
            
            if successful_images > 0:
                print(f"   âœ… El modelo parece estar funcionando correctamente")
            else:
                print(f"   âš ï¸ El modelo no detectÃ³ lÃ¡pices en las imÃ¡genes de prueba")
                print(f"   ğŸ’¡ Esto puede ser normal si las imÃ¡genes son muy diferentes")
                
        else:
            print("âš ï¸ No se encontraron imÃ¡genes de test")
            
    except Exception as e:
        print(f"âŒ Error probando modelo: {e}")

def check_system_requirements():
    """Verificar requisitos del sistema"""
    print("ğŸ” Verificando requisitos del sistema...")
    
    try:
        import ultralytics
        print(f"âœ… Ultralytics: {ultralytics.__version__}")
    except ImportError:
        print("âŒ Ultralytics no encontrado. Instala: pip install ultralytics")
        return False
    
    try:
        import torch
        print(f"âœ… PyTorch: {torch.__version__}")
        print(f"âœ… CUDA disponible: {torch.cuda.is_available()}")
        if torch.cuda.is_available():
            print(f"   â€¢ GPU: {torch.cuda.get_device_name(0)}")
            print(f"   â€¢ Memoria GPU: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
    except ImportError:
        print("âŒ PyTorch no encontrado")
        return False
    
    try:
        import cv2
        print(f"âœ… OpenCV: {cv2.__version__}")
    except ImportError:
        print("âŒ OpenCV no encontrado")
        return False
    
    return True

def main():
    """FunciÃ³n principal"""
    print("ğŸš€ ENTRENADOR DE MODELO CON DATASET DE ROBOFLOW")
    print("="*60)
    print("ğŸ¯ Tu dataset estÃ¡ perfectamente organizado!")
    print("ğŸ“Š Train: 39 imÃ¡genes | Valid: 11 imÃ¡genes | Test: 6 imÃ¡genes")
    print("="*60)
    
    # Verificar requisitos
    if not check_system_requirements():
        print("\nâŒ Faltan requisitos del sistema")
        return
    
    # Verificar dataset
    if not verify_roboflow_dataset():
        print("\nâŒ Problemas con el dataset")
        return
    
    # Verificar etiquetas
    if not validate_sample_labels():
        print("\nâŒ Problemas con las etiquetas")
        return
    
    # Confirmar entrenamiento
    print(f"\nğŸ¯ Â¿Iniciar entrenamiento del modelo de lÃ¡piz?")
    print(f"â³ Tiempo estimado: 15-30 minutos")
    print(f"ğŸ’¾ Espacio necesario: ~500MB")
    
    try:
        choice = input("\nÂ¿Continuar? (s/n): ").lower().strip()
        
        if choice in ['s', 'si', 'sÃ­', 'y', 'yes']:
            print(f"\nğŸš€ Â¡Iniciando entrenamiento!")
            
            model_path = train_lapiz_model()
            
            if model_path:
                print(f"\nğŸŠ Â¡Ã‰XITO TOTAL!")
                print(f"="*60)
                print(f"âœ… Modelo entrenado exitosamente")
                print(f"ğŸ“¦ UbicaciÃ³n: {model_path}")
                print(f"ğŸ¯ Listo para usar en la aplicaciÃ³n")
                
                print(f"\nğŸš€ PRÃ“XIMOS PASOS:")
                print(f"1. Ejecuta: python yolo_detector_escritura.py")
                print(f"2. Carga el modelo: {model_path}")
                print(f"3. Â¡Prueba detectando lÃ¡pices y libros!")
                
                print(f"\nğŸ’¡ RECORDATORIO:")
                print(f"â€¢ El modelo detecta LÃPICES (personalizado)")
                print(f"â€¢ YOLOv8 detecta LIBROS (preentrenado)")
                print(f"â€¢ Cuando estÃ¡n JUNTOS = KIT DE ESCRITURA")
                
            else:
                print(f"\nâŒ Entrenamiento fallÃ³")
                print(f"ğŸ’¡ Revisa los errores anteriores")
                
        else:
            print(f"ğŸ‘‹ Entrenamiento cancelado")
            
    except KeyboardInterrupt:
        print(f"\nâš ï¸ Entrenamiento cancelado por el usuario")
    except Exception as e:
        print(f"\nâŒ Error: {e}")

if __name__ == "__main__":
    main()