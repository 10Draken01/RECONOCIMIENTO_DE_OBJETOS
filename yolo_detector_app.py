"""
YOLO Detector Application - DETECCI√ìN INTELIGENTE DE ESCRITURA
Sistema H√≠brido:
- Modelo preentrenado: Detecta LIBROS (book)
- Modelo personalizado: Detecta L√ÅPICES
- L√≥gica inteligente: Cuando l√°piz + libro est√°n JUNTOS = KIT DE ESCRITURA
"""

import sys
import cv2
import numpy as np
import json
from datetime import datetime
from pathlib import Path
import threading
import time
import os
import math
import random

from PySide6.QtWidgets import (QApplication, QMainWindow, QWidget, QVBoxLayout, 
                              QHBoxLayout, QGridLayout, QLabel, QPushButton, 
                              QFileDialog, QSlider, QCheckBox, QTabWidget,
                              QTextEdit, QProgressBar, QFrame, QSizePolicy,
                              QSpacerItem, QScrollArea, QGroupBox)
from PySide6.QtCore import Qt, QThread, QTimer, Signal, QSize
from PySide6.QtGui import QPixmap, QImage, QFont, QPalette, QColor, QIcon

from ultralytics import YOLO
import torch

# ============================================================================
# DETECTOR H√çBRIDO DE ESCRITURA
# ============================================================================

class YOLOEscrituraHybridDetector:
    """
    Detector h√≠brido de escritura:
    - Usa modelo preentrenado para detectar libros
    - Usa modelo personalizado para detectar l√°pices  
    - Analiza proximidad para identificar kits de escritura
    """
    
    def __init__(self):
        print("‚úèÔ∏èüìö Inicializando Detector H√≠brido de Escritura...")
        
        # Modelos
        self.pretrained_model = None  # YOLOv8 preentrenado (para libros)
        self.lapiz_model = None       # Modelo personalizado (para l√°pices)
        
        # Configuraci√≥n
        self.confidence_threshold = 0.5
        self.iou_threshold = 0.45
        self.proximity_threshold = 150  # Pixeles para considerar objetos "juntos"
        
        # Clases del modelo preentrenado (COCO)
        self.coco_classes = {
            74: 'book',  # Libro en COCO dataset
            # Agregar m√°s clases si necesitas
        }
        
        # Colores para visualizaci√≥n
        self.colors = {
            'lapiz': (0, 255, 0),           # Verde
            'book': (255, 0, 0),            # Azul  
            'kit_escritura': (0, 0, 255),   # Rojo
            'default': (255, 255, 255)      # Blanco
        }
        
        # Cargar modelo preentrenado
        self._load_pretrained_model()
        self.reset_statistics()
        
        print("‚úÖ Detector H√≠brido listo")

    def reset_statistics(self):
        """Reiniciar estad√≠sticas"""
        self.statistics = {
            'total_objects': 0,
            'objects_by_class': {},
            'kits_detected': 0,
            'analysis_timestamp': None
        }
    
    def _load_pretrained_model(self):
        """Cargar modelo YOLO preentrenado"""
        try:
            model_path = "yolov8n.pt"
            if os.path.exists(model_path):
                self.pretrained_model = YOLO(model_path)
                print(f"‚úÖ Modelo preentrenado cargado: {model_path}")
            else:
                self.pretrained_model = YOLO('yolov8n.pt')
                print("‚úÖ Modelo preentrenado descargado y cargado")
        except Exception as e:
            print(f"‚ùå Error cargando modelo preentrenado: {e}")
    
    def load_lapiz_model(self, model_path):
        """Cargar modelo personalizado de l√°piz"""
        try:
            if os.path.exists(model_path):
                self.lapiz_model = YOLO(model_path)
                print(f"‚úÖ Modelo de l√°piz cargado: {model_path}")
                return True
            else:
                print(f"‚ùå No se encontr√≥ el modelo de l√°piz: {model_path}")
                return False
        except Exception as e:
            print(f"‚ùå Error cargando modelo de l√°piz: {e}")
            return False
    
    def detect_objects(self, image):
        """Detectar objetos usando ambos modelos y analizar proximidad"""
        detections = []
        
        # Detecci√≥n con modelo preentrenado (libros)
        if self.pretrained_model:
            book_detections = self._detect_books(image)
            detections.extend(book_detections)
        
        # Detecci√≥n con modelo personalizado (l√°pices)
        if self.lapiz_model:
            lapiz_detections = self._detect_lapices(image)
            detections.extend(lapiz_detections)
        
        # Analizar proximidad para detectar kits
        kit_detections = self._analyze_kits(detections)
        detections.extend(kit_detections)
        
        return detections
    
    def _detect_books(self, image):
        """Detectar libros usando modelo preentrenado"""
        detections = []
        
        try:
            results = self.pretrained_model(image, conf=self.confidence_threshold, iou=self.iou_threshold)
            
            for result in results:
                boxes = result.boxes
                if boxes is not None:
                    for box in boxes:
                        class_id = int(box.cls[0])
                        confidence = float(box.conf[0])
                        bbox = box.xyxy[0].cpu().numpy()
                        
                        # Filtrar solo libros
                        if class_id in self.coco_classes:
                            detection = {
                                'clase': 'book',
                                'clase_nombre': 'Libro',
                                'confianza': confidence,
                                'bbox': [int(bbox[0]), int(bbox[1]), int(bbox[2]), int(bbox[3])],
                                'centro': [int((bbox[0] + bbox[2])/2), int((bbox[1] + bbox[3])/2)],
                                'modelo': 'preentrenado',
                                'class_id': class_id,
                                'tipo': 'individual'
                            }
                            detections.append(detection)
        
        except Exception as e:
            print(f"‚ùå Error detectando libros: {e}")
        
        return detections
    
    def _detect_lapices(self, image):
        """Detectar l√°pices usando modelo personalizado"""
        detections = []
        
        try:
            results = self.lapiz_model(image, conf=self.confidence_threshold, iou=self.iou_threshold)
            
            for result in results:
                boxes = result.boxes
                if boxes is not None:
                    for box in boxes:
                        class_id = int(box.cls[0])
                        confidence = float(box.conf[0])
                        bbox = box.xyxy[0].cpu().numpy()
                        
                        detection = {
                            'clase': 'lapiz',
                            'clase_nombre': 'L√°piz',
                            'confianza': confidence,
                            'bbox': [int(bbox[0]), int(bbox[1]), int(bbox[2]), int(bbox[3])],
                            'centro': [int((bbox[0] + bbox[2])/2), int((bbox[1] + bbox[3])/2)],
                            'modelo': 'personalizado',
                            'class_id': class_id,
                            'tipo': 'individual'
                        }
                        detections.append(detection)
        
        except Exception as e:
            print(f"‚ùå Error detectando l√°pices: {e}")
        
        return detections
    
    def _analyze_kits(self, detections):
        """Analizar proximidad entre l√°pices y libros para detectar kits"""
        kit_detections = []
        
        # Separar detecciones por tipo
        lapices = [d for d in detections if d['clase'] == 'lapiz']
        libros = [d for d in detections if d['clase'] == 'book']
        
        # Buscar pares l√°piz-libro cercanos
        for lapiz in lapices:
            for libro in libros:
                # Calcular distancia entre centros
                dist = math.sqrt(
                    (lapiz['centro'][0] - libro['centro'][0])**2 + 
                    (lapiz['centro'][1] - libro['centro'][1])**2
                )
                
                # Si est√°n lo suficientemente cerca, crear kit
                if dist <= self.proximity_threshold:
                    # Calcular bbox que englobe ambos objetos
                    x1 = min(lapiz['bbox'][0], libro['bbox'][0])
                    y1 = min(lapiz['bbox'][1], libro['bbox'][1])
                    x2 = max(lapiz['bbox'][2], libro['bbox'][2])
                    y2 = max(lapiz['bbox'][3], libro['bbox'][3])
                    
                    # Calcular confianza promedio
                    confidence = (lapiz['confianza'] + libro['confianza']) / 2
                    
                    kit_detection = {
                        'clase': 'kit_escritura',
                        'clase_nombre': 'Kit de Escritura',
                        'confianza': confidence,
                        'bbox': [x1, y1, x2, y2],
                        'centro': [int((x1 + x2)/2), int((y1 + y2)/2)],
                        'modelo': 'h√≠brido',
                        'class_id': 999,  # ID especial para kit
                        'tipo': 'kit',
                        'componentes': {
                            'lapiz': lapiz,
                            'libro': libro
                        },
                        'distancia': round(dist, 1)
                    }
                    kit_detections.append(kit_detection)
        
        return kit_detections
    
    def draw_detections(self, image, detections):
        """Dibujar detecciones en la imagen"""
        annotated_image = image.copy()
        
        # Separar detecciones por tipo para dibujar en orden
        individuales = [d for d in detections if d['tipo'] == 'individual']
        kits = [d for d in detections if d['tipo'] == 'kit']
        
        # Dibujar detecciones individuales primero
        for detection in individuales:
            self._draw_single_detection(annotated_image, detection)
        
        # Dibujar kits despu√©s (m√°s prominentes)
        for detection in kits:
            self._draw_kit_detection(annotated_image, detection)
        
        return annotated_image
    
    def _draw_single_detection(self, image, detection):
        """Dibujar una detecci√≥n individual"""
        bbox = detection['bbox']
        x1, y1, x2, y2 = bbox
        
        color = self.colors.get(detection['clase'], self.colors['default'])
        
        # Dibujar rect√°ngulo
        cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)
        
        # Preparar texto
        confidence = detection['confianza']
        clase_nombre = detection['clase_nombre']
        label = f"{clase_nombre} ({confidence:.2f})"
        
        # Dibujar texto
        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = 0.6
        thickness = 2
        (text_width, text_height), _ = cv2.getTextSize(label, font, font_scale, thickness)
        
        cv2.rectangle(image, (x1, y1 - text_height - 10), 
                     (x1 + text_width, y1), color, -1)
        cv2.putText(image, label, (x1, y1 - 5), 
                   font, font_scale, (255, 255, 255), thickness)
    
    def _draw_kit_detection(self, image, detection):
        """Dibujar detecci√≥n de kit (m√°s prominente)"""
        bbox = detection['bbox']
        x1, y1, x2, y2 = bbox
        
        color = self.colors['kit_escritura']
        
        # Dibujar rect√°ngulo m√°s grueso para kit
        cv2.rectangle(image, (x1, y1), (x2, y2), color, 4)
        
        # Preparar texto del kit
        confidence = detection['confianza']
        distancia = detection['distancia']
        label = f"KIT DE ESCRITURA ({confidence:.2f})"
        sublabel = f"Distancia: {distancia}px"
        
        # Dibujar texto principal
        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = 0.7
        thickness = 2
        
        (text_width, text_height), _ = cv2.getTextSize(label, font, font_scale, thickness)
        (sub_width, sub_height), _ = cv2.getTextSize(sublabel, font, 0.5, 1)
        
        # Fondo del texto
        cv2.rectangle(image, (x1, y1 - text_height - sub_height - 15), 
                     (x1 + max(text_width, sub_width), y1), color, -1)
        
        # Texto principal
        cv2.putText(image, label, (x1, y1 - sub_height - 8), 
                   font, font_scale, (255, 255, 255), thickness)
        
        # Subtexto
        cv2.putText(image, sublabel, (x1, y1 - 2), 
                   font, 0.5, (255, 255, 255), 1)
        
        # Dibujar l√≠nea conectando componentes
        lapiz_centro = detection['componentes']['lapiz']['centro']
        libro_centro = detection['componentes']['libro']['centro']
        cv2.line(image, tuple(lapiz_centro), tuple(libro_centro), color, 2)
        
        # Dibujar puntos en los centros
        cv2.circle(image, tuple(lapiz_centro), 5, color, -1)
        cv2.circle(image, tuple(libro_centro), 5, color, -1)
    
    def count_objects(self, detections):
        """Contar objetos por clase"""
        counts = {}
        
        for detection in detections:
            class_name = detection['clase_nombre']
            if class_name not in counts:
                counts[class_name] = 0
            counts[class_name] += 1
        
        return counts
    
    def analyze_writing_setup(self, detections):
        """Analizar configuraci√≥n de escritura"""
        analysis = {
            'lapices_individuales': len([d for d in detections if d['clase'] == 'lapiz']),
            'libros_individuales': len([d for d in detections if d['clase'] == 'book']),
            'kits_detectados': len([d for d in detections if d['clase'] == 'kit_escritura']),
            'total_objetos': len(detections),
            'configuracion': 'incompleta'
        }
        
        # Determinar tipo de configuraci√≥n
        if analysis['kits_detectados'] > 0:
            analysis['configuracion'] = 'kit_completo'
        elif analysis['lapices_individuales'] > 0 and analysis['libros_individuales'] > 0:
            analysis['configuracion'] = 'elementos_separados'
        elif analysis['lapices_individuales'] > 0:
            analysis['configuracion'] = 'solo_lapices'
        elif analysis['libros_individuales'] > 0:
            analysis['configuracion'] = 'solo_libros'
        
        return analysis
    
    def set_confidence_threshold(self, threshold):
        """Establecer umbral de confianza"""
        self.confidence_threshold = max(0.1, min(1.0, threshold))
    
    def set_iou_threshold(self, threshold):
        """Establecer umbral de IoU"""
        self.iou_threshold = max(0.1, min(1.0, threshold))
    
    def set_proximity_threshold(self, threshold):
        """Establecer umbral de proximidad para kits"""
        self.proximity_threshold = max(50, min(500, threshold))

# ============================================================================
# HILO PARA PROCESAMIENTO DE VIDEO
# ============================================================================

class VideoProcessorThread(QThread):
    """Hilo para procesar video en tiempo real"""
    
    frame_ready = Signal(np.ndarray, dict, dict)
    error_occurred = Signal(str)
    
    def __init__(self):
        super().__init__()
        self.detector = YOLOEscrituraHybridDetector()
        self.running = False
        self.source = None
        self.frame_skip = 1
        self.frame_count = 0
    
    def set_source(self, source):
        """Establecer fuente de video"""
        self.source = source
    
    def start_processing(self):
        """Iniciar procesamiento"""
        self.running = True
        self.start()
    
    def stop_processing(self):
        """Detener procesamiento"""
        self.running = False
        self.wait()
    
    def run(self):
        """Ejecutar procesamiento de video"""
        if self.source is None:
            self.error_occurred.emit("No se ha establecido fuente de video")
            return
        
        # Abrir fuente de video
        if isinstance(self.source, int):
            cap = cv2.VideoCapture(self.source)
        else:
            cap = cv2.VideoCapture(str(self.source))
        
        if not cap.isOpened():
            self.error_occurred.emit(f"No se pudo abrir la fuente: {self.source}")
            return
        
        try:
            while self.running:
                ret, frame = cap.read()
                if not ret:
                    break
                
                self.frame_count += 1
                
                if self.frame_count % self.frame_skip != 0:
                    continue
                
                # Detectar objetos
                detections = self.detector.detect_objects(frame)
                
                # Contar objetos
                counts = self.detector.count_objects(detections)
                
                # Analizar configuraci√≥n
                setup_analysis = self.detector.analyze_writing_setup(detections)
                
                # Dibujar detecciones
                annotated_frame = self.detector.draw_detections(frame, detections)
                
                # Emitir frame procesado
                self.frame_ready.emit(annotated_frame, counts, setup_analysis)
                
                self.msleep(30)
        
        except Exception as e:
            self.error_occurred.emit(f"Error procesando video: {e}")
        
        finally:
            cap.release()

# ============================================================================
# INTERFAZ PRINCIPAL
# ============================================================================

class YOLOEscrituraHybridApp(QMainWindow):
    """Aplicaci√≥n principal del detector h√≠brido de escritura"""
    
    def __init__(self):
        super().__init__()
        self.detector = YOLOEscrituraHybridDetector()
        self.video_processor = VideoProcessorThread()
        self.current_image = None
        self.current_detections = []
        
        self.init_ui()
        self.connect_signals()
        self.apply_dark_theme()
    
    def init_ui(self):
        """Inicializar interfaz de usuario"""
        self.setWindowTitle("‚úèÔ∏èüìö YOLO Detector H√≠brido - L√°piz + Libro = Kit de Escritura")
        self.setGeometry(100, 100, 1400, 900)
        
        # Widget central
        central_widget = QWidget()
        self.setCentralWidget(central_widget)
        
        # Layout principal
        main_layout = QHBoxLayout(central_widget)
        
        # Panel izquierdo - Controles
        self.create_control_panel(main_layout)
        
        # Panel derecho - Visualizaci√≥n
        self.create_display_panel(main_layout)
    
    def create_control_panel(self, main_layout):
        """Crear panel de controles"""
        control_frame = QFrame()
        control_frame.setFixedWidth(380)
        control_frame.setFrameStyle(QFrame.StyledPanel)
        
        control_layout = QVBoxLayout(control_frame)
        
        # T√≠tulo
        title = QLabel("‚úèÔ∏èüìö DETECTOR H√çBRIDO")
        title.setStyleSheet("font-size: 18px; font-weight: bold; color: #00ff88; margin: 10px;")
        title.setAlignment(Qt.AlignCenter)
        control_layout.addWidget(title)
        
        subtitle = QLabel("L√°piz + Libro = Kit")
        subtitle.setStyleSheet("font-size: 12px; color: #888; margin-bottom: 10px;")
        subtitle.setAlignment(Qt.AlignCenter)
        control_layout.addWidget(subtitle)
        
        # Secci√≥n de archivos
        files_group = QGroupBox("üìÅ Archivos")
        files_layout = QVBoxLayout(files_group)
        
        self.btn_load_image = QPushButton("Cargar Imagen")
        self.btn_load_video = QPushButton("Cargar Video")
        self.btn_camera = QPushButton("Usar C√°mara")
        
        files_layout.addWidget(self.btn_load_image)
        files_layout.addWidget(self.btn_load_video)
        files_layout.addWidget(self.btn_camera)
        
        control_layout.addWidget(files_group)
        
        # Secci√≥n de modelos
        models_group = QGroupBox("ü§ñ Modelos")
        models_layout = QVBoxLayout(models_group)
        
        # Estado de modelos
        self.pretrained_status = QLabel("üìö Libros: ‚úÖ Modelo preentrenado")
        self.pretrained_status.setStyleSheet("color: #00ff88; padding: 2px;")
        models_layout.addWidget(self.pretrained_status)
        
        self.lapiz_status = QLabel("‚úèÔ∏è L√°piz: ‚ùå Sin modelo")
        self.lapiz_status.setStyleSheet("color: #ff6666; padding: 2px;")
        models_layout.addWidget(self.lapiz_status)
        
        self.btn_load_lapiz_model = QPushButton("Cargar Modelo L√°piz")
        models_layout.addWidget(self.btn_load_lapiz_model)
        
        control_layout.addWidget(models_group)
        
        # Secci√≥n de configuraci√≥n
        config_group = QGroupBox("‚öôÔ∏è Configuraci√≥n")
        config_layout = QVBoxLayout(config_group)
        
        # Umbral de confianza
        config_layout.addWidget(QLabel("Confianza:"))
        self.confidence_slider = QSlider(Qt.Horizontal)
        self.confidence_slider.setRange(10, 100)
        self.confidence_slider.setValue(50)
        self.confidence_label = QLabel("0.50")
        
        conf_layout = QHBoxLayout()
        conf_layout.addWidget(self.confidence_slider)
        conf_layout.addWidget(self.confidence_label)
        config_layout.addLayout(conf_layout)
        
        # Umbral de proximidad para kits
        config_layout.addWidget(QLabel("Proximidad Kit (px):"))
        self.proximity_slider = QSlider(Qt.Horizontal)
        self.proximity_slider.setRange(50, 300)
        self.proximity_slider.setValue(150)
        self.proximity_label = QLabel("150")
        
        prox_layout = QHBoxLayout()
        prox_layout.addWidget(self.proximity_slider)
        prox_layout.addWidget(self.proximity_label)
        config_layout.addLayout(prox_layout)
        
        control_layout.addWidget(config_group)
        
        # Secci√≥n de estad√≠sticas
        stats_group = QGroupBox("üìä An√°lisis de Escritura")
        stats_layout = QVBoxLayout(stats_group)
        
        self.stats_text = QTextEdit()
        self.stats_text.setMaximumHeight(280)
        self.stats_text.setReadOnly(True)
        stats_layout.addWidget(self.stats_text)
        
        control_layout.addWidget(stats_group)
        
        # Botones de control
        control_buttons_group = QGroupBox("üéÆ Control")
        control_buttons_layout = QVBoxLayout(control_buttons_group)
        
        self.btn_start_stop = QPushButton("‚ñ∂Ô∏è Iniciar")
        self.btn_save_results = QPushButton("üíæ Guardar Resultados")
        
        control_buttons_layout.addWidget(self.btn_start_stop)
        control_buttons_layout.addWidget(self.btn_save_results)
        
        control_layout.addWidget(control_buttons_group)
        
        # Espaciador
        control_layout.addStretch()
        
        main_layout.addWidget(control_frame)
    
    def create_display_panel(self, main_layout):
        """Crear panel de visualizaci√≥n"""
        display_frame = QFrame()
        display_frame.setFrameStyle(QFrame.StyledPanel)
        
        display_layout = QVBoxLayout(display_frame)
        
        # √Årea de imagen/video
        self.image_label = QLabel()
        self.image_label.setMinimumSize(800, 600)
        self.image_label.setStyleSheet("border: 2px solid #333; background-color: #1a1a1a;")
        self.image_label.setAlignment(Qt.AlignCenter)
        self.image_label.setText("Cargar imagen o video\\n\\n‚úèÔ∏è Detecta L√ÅPICES (modelo personalizado)\\nüìö Detecta LIBROS (modelo preentrenado)\\nüéØ Cuando est√°n JUNTOS = KIT DE ESCRITURA")
        
        display_layout.addWidget(self.image_label)
        
        # Barra de estado
        self.status_label = QLabel("Listo - Carga el modelo de l√°piz para comenzar")
        self.status_label.setStyleSheet("color: #00ff88; padding: 5px;")
        display_layout.addWidget(self.status_label)
        
        main_layout.addWidget(display_frame)
    
    def connect_signals(self):
        """Conectar se√±ales"""
        # Botones de archivos
        self.btn_load_image.clicked.connect(self.load_image)
        self.btn_load_video.clicked.connect(self.load_video)
        self.btn_camera.clicked.connect(self.start_camera)
        
        # Botones de modelos
        self.btn_load_lapiz_model.clicked.connect(self.load_lapiz_model)
        
        # Botones de control
        self.btn_start_stop.clicked.connect(self.toggle_processing)
        self.btn_save_results.clicked.connect(self.save_results)
        
        # Sliders
        self.confidence_slider.valueChanged.connect(self.update_confidence)
        self.proximity_slider.valueChanged.connect(self.update_proximity)
        
        # Video processor
        self.video_processor.frame_ready.connect(self.display_frame)
        self.video_processor.error_occurred.connect(self.show_error)
    
    def apply_dark_theme(self):
        """Aplicar tema oscuro"""
        self.setStyleSheet("""
            QMainWindow {
                background-color: #2b2b2b;
                color: #ffffff;
            }
            QGroupBox {
                font-weight: bold;
                border: 2px solid #555;
                border-radius: 5px;
                margin: 5px;
                padding-top: 10px;
            }
            QGroupBox::title {
                subcontrol-origin: margin;
                left: 10px;
                padding: 0 5px 0 5px;
            }
            QPushButton {
                background-color: #404040;
                border: 2px solid #555;
                border-radius: 5px;
                padding: 8px;
                font-weight: bold;
            }
            QPushButton:hover {
                background-color: #505050;
                border-color: #00ff88;
            }
            QPushButton:pressed {
                background-color: #303030;
            }
            QSlider::groove:horizontal {
                border: 1px solid #999999;
                height: 8px;
                background: qlineargradient(x1:0, y1:0, x2:0, y2:1, stop:0 #B1B1B1, stop:1 #c4c4c4);
                margin: 2px 0;
            }
            QSlider::handle:horizontal {
                background: qlineargradient(x1:0, y1:0, x2:1, y2:1, stop:0 #b4b4b4, stop:1 #8f8f8f);
                border: 1px solid #5c5c5c;
                width: 18px;
                margin: -2px 0;
                border-radius: 3px;
            }
            QTextEdit {
                background-color: #1a1a1a;
                border: 1px solid #555;
                border-radius: 3px;
                padding: 5px;
            }
            QLabel {
                color: #ffffff;
            }
        """)
    
    def load_image(self):
        """Cargar imagen"""
        file_path, _ = QFileDialog.getOpenFileName(
            self, "Cargar Imagen", "", 
            "Im√°genes (*.png *.jpg *.jpeg *.bmp *.tiff)"
        )
        
        if file_path:
            image = cv2.imread(file_path)
            if image is not None:
                self.current_image = image
                self.process_image(image)
                self.status_label.setText(f"Imagen cargada: {Path(file_path).name}")
            else:
                self.show_error("No se pudo cargar la imagen")
    
    def load_video(self):
        """Cargar video"""
        file_path, _ = QFileDialog.getOpenFileName(
            self, "Cargar Video", "", 
            "Videos (*.mp4 *.avi *.mov *.mkv *.wmv)"
        )
        
        if file_path:
            self.video_processor.set_source(file_path)
            self.status_label.setText(f"Video cargado: {Path(file_path).name}")
            self.btn_start_stop.setText("‚ñ∂Ô∏è Iniciar Video")
    
    def start_camera(self):
        """Iniciar c√°mara"""
        self.video_processor.set_source(0)
        self.status_label.setText("C√°mara configurada")
        self.btn_start_stop.setText("‚ñ∂Ô∏è Iniciar C√°mara")
    
    def load_lapiz_model(self):
        """Cargar modelo de l√°piz"""
        file_path, _ = QFileDialog.getOpenFileName(
            self, "Cargar Modelo de L√°piz", "", 
            "Modelos YOLO (*.pt *.onnx)"
        )
        
        if file_path:
            success = self.detector.load_lapiz_model(file_path)
            self.video_processor.detector.load_lapiz_model(file_path)
            
            if success:
                self.lapiz_status.setText("‚úèÔ∏è L√°piz: ‚úÖ Modelo cargado")
                self.lapiz_status.setStyleSheet("color: #00ff88; padding: 2px;")
                self.status_label.setText(f"Modelo de l√°piz cargado: {Path(file_path).name}")
            else:
                self.show_error("No se pudo cargar el modelo de l√°piz")
    
    def process_image(self, image):
        """Procesar imagen individual"""
        detections = self.detector.detect_objects(image)
        self.current_detections = detections
        
        annotated_image = self.detector.draw_detections(image, detections)
        self.display_image(annotated_image)
        
        counts = self.detector.count_objects(detections)
        setup_analysis = self.detector.analyze_writing_setup(detections)
        self.update_statistics(counts, detections, setup_analysis)
    
    def toggle_processing(self):
        """Alternar procesamiento de video"""
        if not self.video_processor.running:
            self.video_processor.start_processing()
            self.btn_start_stop.setText("‚èπÔ∏è Detener")
        else:
            self.video_processor.stop_processing()
            self.btn_start_stop.setText("‚ñ∂Ô∏è Iniciar")
    
    def display_frame(self, frame, counts, setup_analysis):
        """Mostrar frame de video"""
        self.display_image(frame)
        self.update_statistics(counts, [], setup_analysis)
    
    def display_image(self, image):
        """Mostrar imagen en la interfaz"""
        height, width, channel = image.shape
        label_size = self.image_label.size()
        
        scale_w = label_size.width() / width
        scale_h = label_size.height() / height
        scale = min(scale_w, scale_h, 1.0)
        
        new_width = int(width * scale)
        new_height = int(height * scale)
        
        resized_image = cv2.resize(image, (new_width, new_height))
        
        rgb_image = cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB)
        h, w, ch = rgb_image.shape
        bytes_per_line = ch * w
        qt_image = QImage(rgb_image.data, w, h, bytes_per_line, QImage.Format_RGB888)
        
        pixmap = QPixmap.fromImage(qt_image)
        self.image_label.setPixmap(pixmap)
    
    def update_statistics(self, counts, detections, setup_analysis):
        """Actualizar estad√≠sticas"""
        stats_text = "üìä AN√ÅLISIS DE ESCRITURA\\n\\n"
        
        # Conteos por clase
        total_objects = sum(counts.values())
        stats_text += f"Total de objetos: {total_objects}\\n\\n"
        
        for class_name, count in counts.items():
            if class_name == "Kit de Escritura":
                stats_text += f"üéØ {class_name}: {count}\\n"
            elif class_name == "L√°piz":
                stats_text += f"‚úèÔ∏è {class_name}: {count}\\n"
            elif class_name == "Libro":
                stats_text += f"üìö {class_name}: {count}\\n"
            else:
                stats_text += f"‚Ä¢ {class_name}: {count}\\n"
        
        # An√°lisis de configuraci√≥n
        if setup_analysis:
            stats_text += "\\nüîç CONFIGURACI√ìN DETECTADA:\\n"
            config = setup_analysis['configuracion']
            
            if config == 'kit_completo':
                stats_text += "‚úÖ Kit de escritura completo\\n"
            elif config == 'elementos_separados':
                stats_text += "‚ö†Ô∏è Elementos separados (no forman kit)\\n"
            elif config == 'solo_lapices':
                stats_text += "üìù Solo l√°pices detectados\\n"
            elif config == 'solo_libros':
                stats_text += "üìñ Solo libros detectados\\n"
            else:
                stats_text += "‚ùå Configuraci√≥n incompleta\\n"
            
            stats_text += f"\\nüìã DETALLES:\\n"
            stats_text += f"   ‚Ä¢ L√°pices individuales: {setup_analysis['lapices_individuales']}\\n"
            stats_text += f"   ‚Ä¢ Libros individuales: {setup_analysis['libros_individuales']}\\n"
            stats_text += f"   ‚Ä¢ Kits detectados: {setup_analysis['kits_detectados']}\\n"
        
        if detections:
            stats_text += "\\nüîé DETECCIONES DETALLADAS:\\n"
            for i, detection in enumerate(detections[:6]):
                clase = detection["clase_nombre"]
                conf = detection["confianza"]
                
                if detection.get('tipo') == 'kit':
                    dist = detection.get('distancia', 0)
                    stats_text += f"{i+1}. üéØ {clase} ({conf:.2f}) - {dist}px\\n"
                else:
                    modelo = detection["modelo"]
                    stats_text += f"{i+1}. {clase} ({conf:.2f}) [{modelo}]\\n"
            
            if len(detections) > 6:
                stats_text += f"... y {len(detections) - 6} m√°s\\n"
        
        self.stats_text.setText(stats_text)
    
    def update_confidence(self, value):
        """Actualizar umbral de confianza"""
        threshold = value / 100.0
        self.confidence_label.setText(f"{threshold:.2f}")
        self.detector.set_confidence_threshold(threshold)
        self.video_processor.detector.set_confidence_threshold(threshold)
    
    def update_proximity(self, value):
        """Actualizar umbral de proximidad"""
        self.proximity_label.setText(str(value))
        self.detector.set_proximity_threshold(value)
        self.video_processor.detector.set_proximity_threshold(value)
    
    def save_results(self):
        """Guardar resultados"""
        if self.current_image is None and not self.current_detections:
            self.show_error("No hay resultados para guardar")
            return
        
        output_dir = Path("output")
        output_dir.mkdir(exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        if self.current_image is not None:
            annotated_image = self.detector.draw_detections(self.current_image, self.current_detections)
            output_path = output_dir / f"hybrid_detection_{timestamp}.jpg"
            cv2.imwrite(str(output_path), annotated_image)
        
        # Guardar resultados
        results = {
            "timestamp": timestamp,
            "detections": self.current_detections,
            "counts": self.detector.count_objects(self.current_detections),
            "setup_analysis": self.detector.analyze_writing_setup(self.current_detections),
            "proximity_threshold": self.detector.proximity_threshold
        }
        
        json_path = output_dir / f"hybrid_results_{timestamp}.json"
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        self.status_label.setText(f"Resultados guardados en: {output_dir}")
    
    def show_error(self, message):
        """Mostrar mensaje de error"""
        self.status_label.setText(f"‚ùå Error: {message}")
        print(f"Error: {message}")

# ============================================================================
# FUNCI√ìN PRINCIPAL
# ============================================================================

def main():
    app = QApplication(sys.argv)
    
    app.setApplicationName("YOLO Detector H√≠brido - Escritura")
    app.setApplicationVersion("2.0")
    
    window = YOLOEscrituraHybridApp()
    window.show()
    
    sys.exit(app.exec())

if __name__ == "__main__":
    main()